{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJQ8loNL5qmAHO1WqHXhS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yukeshhbp/USING-GEMINI-CHATBOT-IN-OUR-OWN-CODE/blob/main/Gemini_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install langchain google-generativeai\n"
      ],
      "metadata": {
        "id": "-PjVoWBlu_5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-google-genai"
      ],
      "metadata": {
        "id": "ic9JzTlxwfkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9648da6f-e70d-402e-d5b4-193f4dde4a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.56)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.3.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10.17)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "LY2JK3NF2Ins"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2vfDs6S2Wot",
        "outputId": "c9ede4d9-2b5a-4174-9c74-479c680eebd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "zdHwIzFF2eM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "ai_msg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5VAH26g2p3D",
        "outputId": "175474f1-8213-4c5f-9677-196e707b1b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-815b55ce-e545-4b28-bbad-fa06198eb431-0', usage_metadata={'input_tokens': 20, 'output_tokens': 7, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3WLr-ZF2vsn",
        "outputId": "6f8bd74e-960e-4a8b-d444-8c0c7ae717be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "J'adore la programmation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n"
      ],
      "metadata": {
        "id": "aY3OC_BL30sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory()"
      ],
      "metadata": {
        "id": "XVVxisgJ36vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=True  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6jbOl4e39tY",
        "outputId": "e3646bef-803a-4b0c-aaee-466736bab86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-df1426b53fc6>:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  chatbot = ConversationChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Chatbot is ready! Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    response = chatbot.run(user_input)\n",
        "    print(f\"Bot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vaj3gMYQ4Ow1",
        "outputId": "c8b296f3-ef6b-4932-e772-ed8bfa52f0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot is ready! Type 'exit' to quit.\n",
            "You: list out some chennai foods\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi\n",
            "AI: Hi there! It's great to be chatting with you. What's on your mind today? I'm ready to answer questions, discuss ideas, or just generally be a helpful AI assistant. I've been trained on a massive dataset of text and code, so I have a pretty broad range of knowledge. Just keep in mind that my knowledge cut-off is sometime in 2022, so I might not be up-to-date on the very latest happenings. But I'll do my best! So, what can I do for you?\n",
            "Human: whats the captial of india\n",
            "AI: The capital of India is New Delhi. It officially became the capital in 1931. Before that, the capital was Calcutta (now Kolkata). New Delhi is located within the National Capital Territory of Delhi and is a planned city, designed by British architect Edwin Lutyens. It's known for its wide, tree-lined avenues and impressive government buildings. Is there anything else you'd like to know about New Delhi or India in general? I can tell you about its history, culture, or even some interesting facts!\n",
            "Human: list out some chennai foods\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: Okay, I can definitely help you with that! Chennai, being a major city in Tamil Nadu, has a vibrant and delicious food scene. Here are some popular Chennai foods, with a little extra detail to whet your appetite:\n",
            "\n",
            "*   **Idli:** These steamed rice cakes are a staple breakfast item. They're soft, fluffy, and usually served with sambar (a lentil-based vegetable stew) and coconut chutney. You can find them everywhere, from street vendors to fancy restaurants.\n",
            "\n",
            "*   **Dosa:** Another South Indian breakfast favorite, dosas are thin, crispy crepes made from fermented rice and lentil batter. They come in many varieties, including masala dosa (filled with a spiced potato mixture), plain dosa, and ghee roast dosa (cooked with clarified butter).\n",
            "\n",
            "*   **Sambar:** As mentioned above, sambar is a lentil-based vegetable stew that's a key accompaniment to idli, dosa, and vada. It's tangy, flavorful, and packed with vegetables like drumsticks, okra, and tomatoes.\n",
            "\n",
            "*   **Vada:** These savory, deep-fried lentil doughnuts are crispy on the outside and soft on the inside. They're often served with sambar and chutney, just like idli and dosa. Medu vada is a popular type.\n",
            "\n",
            "*   **Uttapam:** Think of uttapam as a thicker, savory pancake made from the same batter as dosa. It's often topped with vegetables like onions, tomatoes, and chilies.\n",
            "\n",
            "*   **Pongal:** A rice and lentil dish, pongal comes in two main varieties: Ven Pongal (savory) and Sakkarai Pongal (sweet). Ven Pongal is often seasoned with black pepper, cumin, and ghee.\n",
            "\n",
            "*   **Chicken 65:** A spicy, deep-fried chicken dish that's a popular appetizer. The \"65\" in the name is a bit of a mystery, with various theories about its origin.\n",
            "\n",
            "*   **Chettinad Cuisine:** Chennai has many restaurants serving Chettinad cuisine, which is known for its bold flavors and generous use of spices. Dishes like Chettinad chicken and mutton are must-tries.\n",
            "\n",
            "*   **Filter Coffee:** No Chennai food experience is complete without a cup of strong, aromatic filter coffee. It's typically served in a traditional stainless steel tumbler and davara (a small bowl).\n",
            "\n",
            "*   **Seafood:** Being a coastal city, Chennai has access to fresh seafood. You can find delicious fish curries, prawn dishes, and crab preparations.\n",
            "\n",
            "*   **Kulfi:** A traditional Indian ice cream, kulfi is denser and creamier than regular ice cream. It comes in various flavors, like mango, pistachio, and cardamom.\n",
            "\n",
            "*   **Jigarthanda:** A refreshing and cooling drink, especially popular in the summer. It's made with milk, almond gum, sarsaparilla root syrup, and ice cream.\n",
            "\n",
            "I could go on, but this should give you a good starting point! Are you interested in learning more about any of these dishes, or perhaps getting recommendations for specific restaurants in Chennai?\n",
            "You: can you give simple basic langchain code\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi\n",
            "AI: Hi there! It's great to be chatting with you. What's on your mind today? I'm ready to answer questions, discuss ideas, or just generally be a helpful AI assistant. I've been trained on a massive dataset of text and code, so I have a pretty broad range of knowledge. Just keep in mind that my knowledge cut-off is sometime in 2022, so I might not be up-to-date on the very latest happenings. But I'll do my best! So, what can I do for you?\n",
            "Human: whats the captial of india\n",
            "AI: The capital of India is New Delhi. It officially became the capital in 1931. Before that, the capital was Calcutta (now Kolkata). New Delhi is located within the National Capital Territory of Delhi and is a planned city, designed by British architect Edwin Lutyens. It's known for its wide, tree-lined avenues and impressive government buildings. Is there anything else you'd like to know about New Delhi or India in general? I can tell you about its history, culture, or even some interesting facts!\n",
            "Human: list out some chennai foods\n",
            "AI: Okay, I can definitely help you with that! Chennai, being a major city in Tamil Nadu, has a vibrant and delicious food scene. Here are some popular Chennai foods, with a little extra detail to whet your appetite:\n",
            "\n",
            "*   **Idli:** These steamed rice cakes are a staple breakfast item. They're soft, fluffy, and usually served with sambar (a lentil-based vegetable stew) and coconut chutney. You can find them everywhere, from street vendors to fancy restaurants.\n",
            "\n",
            "*   **Dosa:** Another South Indian breakfast favorite, dosas are thin, crispy crepes made from fermented rice and lentil batter. They come in many varieties, including masala dosa (filled with a spiced potato mixture), plain dosa, and ghee roast dosa (cooked with clarified butter).\n",
            "\n",
            "*   **Sambar:** As mentioned above, sambar is a lentil-based vegetable stew that's a key accompaniment to idli, dosa, and vada. It's tangy, flavorful, and packed with vegetables like drumsticks, okra, and tomatoes.\n",
            "\n",
            "*   **Vada:** These savory, deep-fried lentil doughnuts are crispy on the outside and soft on the inside. They're often served with sambar and chutney, just like idli and dosa. Medu vada is a popular type.\n",
            "\n",
            "*   **Uttapam:** Think of uttapam as a thicker, savory pancake made from the same batter as dosa. It's often topped with vegetables like onions, tomatoes, and chilies.\n",
            "\n",
            "*   **Pongal:** A rice and lentil dish, pongal comes in two main varieties: Ven Pongal (savory) and Sakkarai Pongal (sweet). Ven Pongal is often seasoned with black pepper, cumin, and ghee.\n",
            "\n",
            "*   **Chicken 65:** A spicy, deep-fried chicken dish that's a popular appetizer. The \"65\" in the name is a bit of a mystery, with various theories about its origin.\n",
            "\n",
            "*   **Chettinad Cuisine:** Chennai has many restaurants serving Chettinad cuisine, which is known for its bold flavors and generous use of spices. Dishes like Chettinad chicken and mutton are must-tries.\n",
            "\n",
            "*   **Filter Coffee:** No Chennai food experience is complete without a cup of strong, aromatic filter coffee. It's typically served in a traditional stainless steel tumbler and davara (a small bowl).\n",
            "\n",
            "*   **Seafood:** Being a coastal city, Chennai has access to fresh seafood. You can find delicious fish curries, prawn dishes, and crab preparations.\n",
            "\n",
            "*   **Kulfi:** A traditional Indian ice cream, kulfi is denser and creamier than regular ice cream. It comes in various flavors, like mango, pistachio, and cardamom.\n",
            "\n",
            "*   **Jigarthanda:** A refreshing and cooling drink, especially popular in the summer. It's made with milk, almond gum, sarsaparilla root syrup, and ice cream.\n",
            "\n",
            "I could go on, but this should give you a good starting point! Are you interested in learning more about any of these dishes, or perhaps getting recommendations for specific restaurants in Chennai?\n",
            "Human: can you give simple basic langchain code\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: I can definitely provide you with some simple, basic Langchain code examples! Langchain is a powerful framework, but it can be a bit overwhelming at first. Let's start with a very basic example of using Langchain to interact with a language model.\n",
            "\n",
            "**Example 1: Simple LLM Chain**\n",
            "\n",
            "This example demonstrates how to use Langchain to create a simple chain that takes a prompt and passes it to a language model (in this case, OpenAI's `gpt-3.5-turbo`).\n",
            "\n",
            "```python\n",
            "import os\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.chains import LLMChain\n",
            "from langchain.prompts import PromptTemplate\n",
            "\n",
            "# Set your OpenAI API key (replace with your actual key)\n",
            "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
            "\n",
            "# 1. Define the LLM\n",
            "llm = OpenAI(temperature=0.7)  # You can adjust the temperature for more or less randomness\n",
            "\n",
            "# 2. Define a Prompt Template\n",
            "prompt_template = PromptTemplate(\n",
            "    input_variables=[\"topic\"],\n",
            "    template=\"Tell me a short story about: {topic}\"\n",
            ")\n",
            "\n",
            "# 3. Create the LLMChain\n",
            "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
            "\n",
            "# 4. Run the Chain\n",
            "story = chain.run(\"a friendly dragon\")\n",
            "\n",
            "# 5. Print the Output\n",
            "print(story)\n",
            "```\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "1.  **Import necessary modules:**  We import `OpenAI` for the language model, `LLMChain` to create the chain, and `PromptTemplate` to define the prompt.\n",
            "2.  **Set OpenAI API Key:**  You *must* replace `\"YOUR_OPENAI_API_KEY\"` with your actual OpenAI API key.  You can get one from the OpenAI website.  Setting it as an environment variable is a common practice.\n",
            "3.  **Define the LLM:**  We initialize an `OpenAI` object.  The `temperature` parameter controls the randomness of the output.  A higher temperature (e.g., 0.7) will result in more creative and unpredictable responses, while a lower temperature (e.g., 0.2) will result in more focused and deterministic responses.\n",
            "4.  **Define a Prompt Template:**  We create a `PromptTemplate` that takes a single input variable, `topic`, and uses it to construct a prompt for the language model.  The template string uses curly braces `{}` to indicate where the input variable should be inserted.\n",
            "5.  **Create the LLMChain:**  We create an `LLMChain` by passing in the `llm` and `prompt_template` objects.  The `LLMChain` is responsible for taking the input, formatting it using the prompt template, passing it to the language model, and returning the output.\n",
            "6.  **Run the Chain:**  We call the `run()` method of the `LLMChain` to execute the chain.  We pass in the value \"a friendly dragon\" as the input for the `topic` variable.\n",
            "7.  **Print the Output:**  We print the output of the chain, which is the short story generated by the language model.\n",
            "\n",
            "**Example 2:  Using a Different LLM (Hugging Face)**\n",
            "\n",
            "If you want to use a Hugging Face model instead of OpenAI, you'll need to install the `huggingface_hub` and `transformers` libraries:\n",
            "\n",
            "```bash\n",
            "pip install huggingface_hub transformers\n",
            "```\n",
            "\n",
            "Then, you can use the following code:\n",
            "\n",
            "```python\n",
            "import os\n",
            "from langchain.llms import HuggingFaceHub\n",
            "from langchain.chains import LLMChain\n",
            "from langchain.prompts import PromptTemplate\n",
            "\n",
            "# Set your Hugging Face API key (if required by the model)\n",
            "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR_HUGGINGFACE_API_TOKEN\"\n",
            "\n",
            "# 1. Define the LLM (replace with a suitable model)\n",
            "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\": 0.7, \"max_length\": 500})\n",
            "\n",
            "# 2. Define a Prompt Template\n",
            "prompt_template = PromptTemplate(\n",
            "    input_variables=[\"question\"],\n",
            "    template=\"Answer the following question: {question}\"\n",
            ")\n",
            "\n",
            "# 3. Create the LLMChain\n",
            "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
            "\n",
            "# 4. Run the Chain\n",
            "answer = chain.run(\"What is the capital of France?\")\n",
            "\n",
            "# 5. Print the Output\n",
            "print(answer)\n",
            "```\n",
            "\n",
            "**Important Notes for Hugging Face:**\n",
            "\n",
            "*   **Model Selection:**  Choose a suitable model from the Hugging Face Hub ([https://huggingface.co/models](https://huggingface.co/models)).  The `repo_id` specifies the model repository.  `google/flan-t5-xl` is a decent starting point, but you might want to explore others.  Some models require an API token.\n",
            "*   **API Token (Optional):**  Some Hugging Face models require an API token. If the model you choose requires one, you'll need to set the `HUGGINGFACEHUB_API_TOKEN` environment variable.  You can get a token from the Hugging Face website.\n",
            "*   **Model Arguments:**  The `model_kwargs` dictionary allows you to pass additional arguments to the model, such as `temperature` and `max_length`.  Refer to the documentation for the specific model you're using to see what arguments are available.\n",
            "\n",
            "**Key Concepts:**\n",
            "\n",
            "*   **LLM (Language Model):** The core component that generates text.  Examples include OpenAI's GPT models and various models on the Hugging Face Hub.\n",
            "*   **Prompt Template:**  A way to structure the input you send to the LLM.  It allows you to define variables that can be filled in with specific values.\n",
            "*   **LLMChain:**  A chain that combines an LLM and a prompt template.  It takes input, formats it using the prompt template, passes it to the LLM, and returns the output.\n",
            "\n",
            "**Next Steps:**\n",
            "\n",
            "These are very basic examples.  To learn more about Langchain, you can explore the following:\n",
            "\n",
            "*   **Different Chain Types:** Langchain offers various chain types for different tasks, such as sequential chains, retrieval chains, and conversational chains.\n",
            "*   **Memory:**  Langchain provides memory modules that allow you to store and retrieve information from previous interactions, enabling you to build conversational agents.\n",
            "*   **Document Loaders:**  Langchain can load documents from various sources, such as text files, PDFs, and websites.\n",
            "*   **Indexes:**  Langchain can create indexes of your documents, allowing you to quickly retrieve relevant information.\n",
            "*   **Agents:**  Langchain agents can use LLMs to decide which tools to use to accomplish a task.\n",
            "\n",
            "Remember to consult the official Langchain documentation ([https://python.langchain.com/](https://python.langchain.com/)) for more detailed information and examples.  Good luck! Let me know if you have any more questions.\n",
            "You: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"who is the president of india 2025\"\n",
        "print(llm.predict(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdTBJFxr4ebp",
        "outputId": "bd5c1e3f-e8b9-42cd-9213-7bffe6eba461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The President of India in 2025 will depend on the election held in 2022. The current President is Droupadi Murmu, who assumed office in July 2022. Her term will last until 2027, unless unforeseen circumstances arise.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UpsXyTBAHUCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}